(WIP) README 

PPO
- Current implementation on Cartpole is very basic, one should anticipate challenges scaling to more difficult tasks
- Resources for this:
- https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/
- https://arxiv.org/pdf/2005.12729

An implementation of PPO on Cartpole, to demonstrate basic learning. This will be built upon later.

SFT

Reference:

Activate virtual environment with `source torch_env/bin/activate`, install stuff with `python -m pip install <stuff>`

Run with `python3 -m experiments`

Show tensorboard with `tensorboard --logdir=./runs`

